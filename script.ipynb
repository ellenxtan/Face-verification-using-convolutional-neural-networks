{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11785-hw2p2-submit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFWb4s-h_inK"
      },
      "source": [
        "# Face Verification Using Convolutional Neural Networks\n",
        "- Task description: Design an end-to-end system for face verification with Convolutional Neural Networks (CNNs). Your system will be given two images as input and will output a score that quantifies the similarity between the faces in these images. This helps us decide whether the faces from the two images are of the same person or not.\n",
        "- Evaluation: The Receiver Operating Characteristic (ROC) curve is created by plotting the True Positive Rate (TPR) against the False Positive Rate (FPR) at various threshold settings. The Area Under the Curve (AUC) for the ROC curve is equal to the probability that a classifier will rank a randomly chosen similar pair (images of same people) higher than a randomly chosen dissimilar one (images from two different people) (assuming 'similar' ranks higher than 'dissimilar' in terms of similarity scores).\n",
        "- [Kaggle competition link](https://www.kaggle.com/c/11-785-fall-20-homework-2-part-2)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sXQbX4H_tdW"
      },
      "source": [
        "## Performance\n",
        "\n",
        "- Epoch for the best result = 68.\n",
        "- Ranking top 3% (5 out of 233) [[Kaggle leaderboard]](https://www.kaggle.com/c/11-785-fall-20-homework-2-part-2/leaderboard).\n",
        "- Classification task:\n",
        "    - training accuracy = 100%, loss = 0.0047.\n",
        "    - validation accuracy = 89.74%, loss = 0.4977.\n",
        "- Verification task:\n",
        "    - validation AUC = 0.9712.\n",
        "    - testing AUC = 0.9716 (at Kaggle)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPAzaQk03OCQ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx2YFqjK3XIN"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/gdrive/My\\ Drive/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!ls -l ~/.kaggle\n",
        "# !cat ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezyv1nYg3alq"
      },
      "source": [
        "# !pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "# !kaggle datasets download -d cmu11785/20fall-hw2p2 -p /content/gdrive/My\\ Drive/hw2p2/mydata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-N43Svh34So"
      },
      "source": [
        "# mypath = \"/content/gdrive/My Drive/hw2p2/mydata/\"\n",
        "# import os\n",
        "# os.chdir(mypath)  #change dir\n",
        "# !ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2IbMpJa34lp"
      },
      "source": [
        "# !unzip 20fall-hw2p2.zip -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we8_EeV6UDhY"
      },
      "source": [
        "# import os\n",
        "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smawYDg4t-2x",
        "outputId": "f9911fa5-201c-4d0a-8c4d-9169c9573d87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision   \n",
        "import sys\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from sklearn.metrics import roc_auc_score\n",
        "print(np.__version__)\n",
        "print(torch.__version__)\n",
        "cuda = torch.cuda.is_available()\n",
        "cuda"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.18.5\n",
            "1.6.0+cu101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc0xF3cLvkZD"
      },
      "source": [
        "## Load data (Torchvision DataSet and DataLoader)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cd3jvQjvlSX"
      },
      "source": [
        "mypath = \"/content/gdrive/My Drive/hw2p2/\"\n",
        "mydatapath = mypath + \"mydata/\"\n",
        "class_data_path = mydatapath + \"classification_data/\"\n",
        "verify_pairs_test_path = mydatapath + \"verification_pairs_test.txt\"\n",
        "verify_pairs_val_path = mydatapath + \"verification_pairs_val.txt\"\n",
        "result_path = mypath + \"results/\"\n",
        "\n",
        "num_workers = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3FjXOy0Q13u"
      },
      "source": [
        "## train data for classification / verification task\n",
        "start_time = time.time()\n",
        "train_set = torchvision.datasets.ImageFolder(root = class_data_path+\"train_data/\", \n",
        "                                             transform = torchvision.transforms.Compose([\n",
        "                                                    torchvision.transforms.RandomHorizontalFlip(),\n",
        "                                                    torchvision.transforms.ToTensor(),\n",
        "                                                    ]))\n",
        "train_loader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=8)\n",
        "print(\"Time to load train data for classify task: \", (time.time() - start_time)/60, \"mins\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG5CiXtSbXEZ"
      },
      "source": [
        "## validation data for classification task\n",
        "start_time = time.time()\n",
        "val_set = torchvision.datasets.ImageFolder(root = class_data_path+\"val_data/\", \n",
        "                                          transform = torchvision.transforms.Compose([\n",
        "                                                    torchvision.transforms.ToTensor(),\n",
        "                                                    ]))\n",
        "val_loader = DataLoader(val_set, batch_size=128, shuffle=False, num_workers=num_workers)\n",
        "print(\"Time to load val data for classify task: \", (time.time() - start_time)/60, \"mins\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKfcj2IWPUhh"
      },
      "source": [
        "# img0 = val_set.__getitem__(0)\n",
        "# img0_x = img0[0].numpy()\n",
        "# img0_y = img0[1]\n",
        "# print(img0_x, img0_y)\n",
        "# plt.imshow(img0_x.transpose((1,2,0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbpWlQL2kAnE"
      },
      "source": [
        "def readFile(path, test):\n",
        "    \"\"\"Load verification data\"\"\"\n",
        "    f = open(path, \"rt\").read().split('\\n')\n",
        "    img1s = []\n",
        "    img2s = []\n",
        "    labels = []\n",
        "    for i, row in enumerate(f):\n",
        "        row = row.split()\n",
        "        if len(row) != 0:\n",
        "            img1s.append(row[0])\n",
        "            img2s.append(row[1])\n",
        "            if not test:\n",
        "                labels.append(int(row[2]))\n",
        "            else:\n",
        "                labels.append(-1)\n",
        "    return img1s, img2s, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odwFXEXKkZBv"
      },
      "source": [
        "class VerificationDataset(Dataset):\n",
        "    \"\"\"Dataset for Verification task\"\"\"\n",
        "    def __init__(self, file_list1, file_list2, target_list=None):\n",
        "        self.file_list1 = file_list1\n",
        "        self.file_list2 = file_list2\n",
        "        self.target_list = target_list\n",
        "\n",
        "    def __len__(self):\n",
        "        assert len(self.file_list1) == len(self.file_list2)\n",
        "        return len(self.file_list1)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img1 = Image.open(mydatapath+self.file_list1[index])\n",
        "        img1 = torchvision.transforms.ToTensor()(img1)\n",
        "        img2 = Image.open(mydatapath+self.file_list2[index])\n",
        "        img2 = torchvision.transforms.ToTensor()(img2)\n",
        "        if self.target_list != None:\n",
        "            label = self.target_list[index]\n",
        "        else:\n",
        "            label = -1\n",
        "        return img1, img2, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5o-F-tlkhpy"
      },
      "source": [
        "## Read pair val data for verification task\n",
        "verify_img1s_val, verify_img2s_val, verify_labels_val = readFile(verify_pairs_val_path, test=False)\n",
        "\n",
        "## load val dataset and dataLoader for verification task\n",
        "start_time = time.time()\n",
        "verify_val_set = VerificationDataset(verify_img1s_val, verify_img2s_val, verify_labels_val)\n",
        "verify_val_loader = DataLoader(verify_val_set, batch_size=128, shuffle=False, num_workers=num_workers, drop_last=False)\n",
        "print(\"Time to load val data for verify task: \", (time.time() - start_time)/60, \"mins\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1dmbr0xZzkE"
      },
      "source": [
        "## CNN Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6J4dB73P-qF"
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels,stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # shortcut\n",
        "        self.conv3_sc = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, bias=False)\n",
        "        self.bn3_sc = nn.BatchNorm2d(out_channels)\n",
        "   \n",
        "    def forward(self,x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        residual = self.bn3_sc(self.conv3_sc(x))  # dotted line in Fig3 in ResNet paper\n",
        "        out += residual\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class IdentityBlock(nn.Module):  \n",
        "    \"\"\"IdentityBlock has same in_channels and out_channels shape\"\"\"\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=1, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        residual = x   # solid line in Fig3 in ResNet paper\n",
        "        out += residual\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Resnet34(nn.Module):\n",
        "    def __init__(self,classes=4000):\n",
        "        super().__init__()\n",
        "        # conv1\n",
        "        self.conv1 = nn.Conv2d(3,64,kernel_size=3,stride=1,padding=1,bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        # conv2_x - *3\n",
        "        self.conv2 = ConvBlock(64,64,stride=1)\n",
        "        self.iden21 = IdentityBlock(64)\n",
        "        self.iden22 = IdentityBlock(64)\n",
        "\n",
        "        # conv3_x: down sample - stride 2, *4\n",
        "        self.conv3 = ConvBlock(64,128,stride=2)\n",
        "        self.iden31 = IdentityBlock(128)\n",
        "        self.iden32 = IdentityBlock(128)\n",
        "        self.iden33 = IdentityBlock(128)\n",
        "\n",
        "        # conv4_x: down sample - stride 2, *6\n",
        "        self.conv4 = ConvBlock(128,256,stride=2)\n",
        "        self.iden41 = IdentityBlock(256)\n",
        "        self.iden42 = IdentityBlock(256)\n",
        "        self.iden43 = IdentityBlock(256)\n",
        "        self.iden44 = IdentityBlock(256)\n",
        "        self.iden45 = IdentityBlock(256)\n",
        "\n",
        "        # conv5_x: down sample - stride 2, *3\n",
        "        self.conv5 = ConvBlock(256,512,stride=2)\n",
        "        self.iden51 = IdentityBlock(512)\n",
        "        self.iden52 = IdentityBlock(512)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512,classes,bias = False)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.iden21(x)\n",
        "        x = self.iden22(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.iden31(x)\n",
        "        x = self.iden32(x)\n",
        "        x = self.iden33(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = self.iden41(x)\n",
        "        x = self.iden42(x)\n",
        "        x = self.iden43(x)\n",
        "        x = self.iden44(x)\n",
        "        x = self.iden45(x)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x = self.iden51(x)\n",
        "        x = self.iden52(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "        out = self.fc(x)/torch.norm(self.fc.weight,dim=1)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA3rn5QIaF3w"
      },
      "source": [
        "## Training & validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0lkSRtbPUVk"
      },
      "source": [
        "def train_epoch(model, train_loader):\n",
        "    model.to(device)\n",
        "    \n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "    avg_loss = 0.0\n",
        "    for batch_num, (feats, labels) in enumerate(train_loader):\n",
        "        feats, labels = feats.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # NEW\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(feats)\n",
        "            loss = criterion(outputs, labels.long())\n",
        "\n",
        "        # NEW: Scales the loss, and calls backward() to create scaled gradients\n",
        "        scaler.scale(loss).backward()\n",
        "        # NEW: Unscales gradients and calls or skips optimizer.step()\n",
        "        scaler.step(optimizer)\n",
        "        # NEW: Updates the scale for next iteration\n",
        "        scaler.update()\n",
        "\n",
        "        # loss.backward()\n",
        "        # optimizer.step()\n",
        "        \n",
        "        avg_loss += loss.item()\n",
        "\n",
        "        if batch_num % 200 == 0:\n",
        "            print('Batch: {}; avg loss: {:.4f}'.format(batch_num, avg_loss/50), \n",
        "                  \"; time:{:.4f} mins\".format((time.time()-start_time)/60))\n",
        "            avg_loss = 0.0    \n",
        "        \n",
        "        torch.cuda.empty_cache()\n",
        "        del feats\n",
        "        del labels\n",
        "        del loss\n",
        "\n",
        "    print(\"*Epoch traing time:{:.4f} mins\".format((time.time()-start_time)/60))\n",
        "    train_loss, train_acc = test_classify(model, train_loader)\n",
        "    return train_loss, train_acc\n",
        "\n",
        "\n",
        "def test_classify(model, val_loader):\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        test_loss = []\n",
        "        accuracy = 0\n",
        "        total = 0\n",
        "        for batch_num, (feats, labels) in enumerate(val_loader):\n",
        "            feats, labels = feats.to(device), labels.to(device)\n",
        "            outputs = model(feats)\n",
        "\n",
        "            _, pred_labels = torch.max(F.softmax(outputs, dim=1), 1)\n",
        "            pred_labels = pred_labels.view(-1)\n",
        "            \n",
        "            loss = criterion(outputs, labels.long())\n",
        "            \n",
        "            accuracy += torch.sum(torch.eq(pred_labels, labels)).item()\n",
        "            total += len(labels)\n",
        "            test_loss.extend([loss.item()]*feats.size()[0])\n",
        "            del feats\n",
        "            del labels\n",
        "\n",
        "    print(\"*Classify time:{:.4f} mins\".format((time.time()-start_time)/60))\n",
        "    return np.mean(test_loss), accuracy/total\n",
        "\n",
        "\n",
        "def test_verify(model, val_loader, test=False):\n",
        "    start_time = time.time()\n",
        "    sim_preds = np.array([])\n",
        "    sim_true = np.array([])\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for batch_num, (imgs1, imgs2, labels) in enumerate(val_loader):\n",
        "            imgs1, imgs2 = imgs1.to(device), imgs2.to(device)\n",
        "            \n",
        "            if not test:\n",
        "                sim_true = np.concatenate((sim_true, labels.numpy().reshape(-1)))\n",
        "                del labels\n",
        "            \n",
        "            imgs1_out = model(imgs1)\n",
        "            imgs2_out = model(imgs2)\n",
        "            sim_pred = F.cosine_similarity(imgs1_out, imgs2_out) \n",
        "            sim_preds = np.concatenate((sim_preds, sim_pred.cpu().numpy().reshape(-1)))\n",
        "\n",
        "            if batch_num % 50 == 0:\n",
        "                print(\"Batch: {}; time:{:.4f} mins\".format(batch_num, (time.time()-start_time)/60))\n",
        "                if not test:\n",
        "                    auc = roc_auc_score(sim_true, sim_preds)\n",
        "                    print(\"***Verify task: val AUC = \", round(auc,4))\n",
        "            del imgs1\n",
        "            del imgs2\n",
        "\n",
        "    # calculate auc at last\n",
        "    if not test:\n",
        "        auc = roc_auc_score(sim_true, sim_preds)\n",
        "    else:\n",
        "        auc = None\n",
        "    print(\"*Verify time:{:.4f} mins\".format((time.time()-start_time)/60))\n",
        "    return sim_preds, sim_true, auc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZQYOgis5Vsv"
      },
      "source": [
        "## Begin training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGzT9mYhVLEi"
      },
      "source": [
        "model = Resnet34() #Network(num_feats, hidden_sizes, num_classes) # \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "learningRate = 0.15 #1e-2\n",
        "weightDecay = 5e-5\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate, weight_decay=weightDecay, momentum=0.9)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", patience=2, factor=0.85)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QuP2qYfUIu9"
      },
      "source": [
        "def init_weights(m):\n",
        "    if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n",
        "\n",
        "model.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3Z3JzSxGDWf"
      },
      "source": [
        "# last_epoch_trained_upon = 68\n",
        "\n",
        "# model_version = \"resNet34_aug_\" + str(last_epoch_trained_upon)\n",
        "# temp = torch.load(result_path + model_version)\n",
        "# model.load_state_dict(temp['model_state_dict'])\n",
        "# criterion.load_state_dict(temp['criterion_state_dict'])\n",
        "# optimizer.load_state_dict(temp['optimizer_state_dict'])\n",
        "# scheduler.load_state_dict(temp['scheduler_state_dict'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95sLjgoKl830"
      },
      "source": [
        "device = torch.device('cuda')  # 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ivc_QMde40-i"
      },
      "source": [
        "# last_epoch_trained_upon = -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP7cYyVOpgq2"
      },
      "source": [
        "model_version = \"resNet34_aug\"\n",
        "numEpochs = 100\n",
        "\n",
        "# NEW: Creates once at the beginning of training\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "# scaler.load_state_dict(temp['scaler_state_dict'])\n",
        "for epoch in range(last_epoch_trained_upon+1, numEpochs):\n",
        "    start_time0 = time.time()\n",
        "    print(epoch)\n",
        "    ## train\n",
        "    train_loss, train_acc = train_epoch(model, train_loader) # about 1900 batchs\n",
        "    print('***Classfy task: train loss: {:.4f}; train acc: {:.4f}'.format(train_loss, train_acc))\n",
        "    ## eval mode\n",
        "    # classification task\n",
        "    val_loss, val_acc = test_classify(model, val_loader)\n",
        "    scheduler.step(val_loss)\n",
        "    print('***Classfy task: val loss: {:.4f}; val acc: {:.4f}'.format(val_loss, val_acc))\n",
        "    # verification task\n",
        "    _, _, verify_auc_val = test_verify(model, verify_val_loader)\n",
        "    print(\"***Verify task: val AUC = \", round(verify_auc_val,4))\n",
        "    print(\"*Whole epoch time:{:.4f} mins\".format(epoch, (time.time()-start_time0)/60))   \n",
        "    print('='*20)\n",
        "\n",
        "    torch.save({\n",
        "        \"epoch\": epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'criterion_state_dict' : criterion.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scheduler_state_dict': scheduler.state_dict(),\n",
        "        'scaler_state_dict': scaler.state_dict(),\n",
        "        'train_loss': train_loss,\n",
        "        \"train_acc\": train_acc,\n",
        "        'val_loss': val_loss,\n",
        "        'val_acc': val_acc,\n",
        "        'verify_auc_val': verify_auc_val\n",
        "    }, result_path + model_version + \"_\" + str(epoch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIhBtdiL6Cga"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uESXnO2_aVF6"
      },
      "source": [
        "### Prediction of test data for verification task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYTOfo2Pf5o5"
      },
      "source": [
        "# best_epoch = 68  # auc 0.9714\n",
        "\n",
        "# model_version = \"resNet34_aug_\" + str(best_epoch)\n",
        "# temp = torch.load(result_path + model_version)\n",
        "# model.load_state_dict(temp['model_state_dict'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHXtBFsggEjd"
      },
      "source": [
        "# device = torch.device('cuda')  # 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn_B__CcGADt"
      },
      "source": [
        "## Read pair test data for verification task\n",
        "verify_img1s_test, verify_img2s_test, _ = readFile(verify_pairs_test_path, test=True)\n",
        "\n",
        "## load test dataset and dataLoader for verification task\n",
        "verify_test_set = VerificationDataset(verify_img1s_test, verify_img2s_test)\n",
        "verify_test_loader = DataLoader(verify_test_set, batch_size=200, shuffle=False, num_workers=num_workers, drop_last=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAqKJix6Et-7"
      },
      "source": [
        "sim_preds_test, _, _ = test_verify(model, verify_test_loader, test=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJueSGo00g4B"
      },
      "source": [
        "sim_preds_test[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8N2s0iT1RtY"
      },
      "source": [
        "# for i in range(len(sim_preds_test)):\n",
        "#     if sim_preds_test[i] >= 0.8:\n",
        "#         sim_preds_test[i] = 1\n",
        "#     if sim_preds_test[i] <= 0.2:\n",
        "#         sim_preds_test[i] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnTz-Q3fS0lY"
      },
      "source": [
        "# sim_preds_test[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22MXR20fICbL"
      },
      "source": [
        "verify_test_file = open(verify_pairs_test_path, \"rt\").read().split('\\n')\n",
        "\n",
        "out_file = mypath + model_version + \"res.csv\"\n",
        "with open(out_file, 'w') as w:\n",
        "    w.write('id,Category\\n')\n",
        "    for i in range(len(sim_preds_test)):\n",
        "        w.write(str(verify_test_file[i])+','+str(sim_preds_test[i])+'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNjGFgygINdp",
        "outputId": "9fbccd60-b6dd-41bf-e7d9-f4c065f3bfaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(sim_preds_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "51835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLyoQuAXIOA-"
      },
      "source": [
        "import pandas as pd\n",
        "out_csv = pd.read_csv(out_file, sep='\\t')\n",
        "out_csv = np.array(out_csv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8Uv_2ayJSDx"
      },
      "source": [
        "out_csv.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBtsvODNJU4n"
      },
      "source": [
        "out_csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U55YB4vJJXbl"
      },
      "source": [
        "!kaggle competitions submit -c 11-785-fall-20-homework-2-part-2 -f /content/gdrive/My\\ Drive/hw2p2/resNet34_aug_68res.csv -m \"Message\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deodpzBdAGAW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}